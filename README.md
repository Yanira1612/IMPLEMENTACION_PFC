# IMPLEMENTACION_PFC

# üß† Detecci√≥n de Sarcasmo en Espa√±ol

Este proyecto tiene como objetivo entrenar y evaluar modelos de lenguaje para la detecci√≥n autom√°tica de sarcasmo en textos en espa√±ol utilizando modelos basados en transformers.

## üîÑ Cambios recientes

### üìÇ Cambio de base de datos

Se ha reemplazado el dataset anterior por uno nuevo m√°s adecuado para el idioma espa√±ol:

- **Nuevo dataset**: [`Ernesto-1997/Sarcastic_spanish_dataset`](https://huggingface.co/datasets/Ernesto-1997/Sarcastic_spanish_dataset)
- **Ventajas**:
  - Dataset p√∫blico y disponible en Hugging Face.
  - Enfocado en iron√≠a y sarcasmo.
  - Datos balanceados y etiquetados para clasificaci√≥n binaria.

### üß™ Modelos probados

Se probaron dos variantes de modelos preentrenados en espa√±ol para evaluar el rendimiento en la tarea de detecci√≥n de sarcasmo:

---

#### ‚úÖ Modelo 1: **BETO** (BERT-base en espa√±ol)
- Repositorio: [`dccuchile/bert-base-spanish-wwm-uncased`](https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased)
- Arquitectura: `AutoModelForSequenceClassification`
- Tipo: modelo est√°ndar sin capas adicionales (no RNN).
- Salida: 1 solo logit ‚Üí funci√≥n `BCEWithLogitsLoss` para clasificaci√≥n binaria.

---

#### ‚úÖ Modelo 2: **BERTUIT** (Robertuito-base uncased)
- Repositorio: [`pysentimiento/robertuito-base-uncased`](https://huggingface.co/pysentimiento/robertuito-base-uncased)
- Arquitectura: `AutoModelForSequenceClassification`
- Tipo: modelo compacto preentrenado para espa√±ol con buena cobertura de lenguaje informal.
- Tambi√©n se us√≥ sin capas adicionales (sin RNN).

---

## ‚öôÔ∏è Entrenamiento

- Ambos modelos fueron entrenados usando la misma arquitectura de entrenamiento:
  - `BCEWithLogitsLoss` con `pos_weight` para manejar desbalanceo.
  - `Adam` optimizador.
  - Evaluaci√≥n con m√©tricas: accuracy, precision, recall, F1, AUC.
- Divisiones: 80% entrenamiento, 10% validaci√≥n, 10% prueba.

---

## üìä Evaluaci√≥n

Cada modelo fue evaluado usando el mismo conjunto de prueba con m√©tricas est√°ndar para comparar su rendimiento en la clasificaci√≥n binaria (sarcasmo vs no sarcasmo).



